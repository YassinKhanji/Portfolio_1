{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def run_strategy():\n",
    "    # Execute the strategy immediately on startup\n",
    "    print(\"Running strategy at\", datetime.now())\n",
    "    # Add your trading strategy logic here\n",
    "    # Make a csv that contains the first set of data for the optimization\n",
    "\n",
    "    while True:\n",
    "        # Get current time and calculate next hour\n",
    "        now = datetime.now()\n",
    "        next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "        # Wait until the next hour\n",
    "        sleep_duration = (next_hour - now).total_seconds()\n",
    "        print(f\"Sleeping for {sleep_duration} seconds...\")\n",
    "        time.sleep(sleep_duration)\n",
    "\n",
    "        # Execute your strategy\n",
    "        print(\"Running strategy at\", datetime.now())\n",
    "        # Add your trading strategy logic here\n",
    "\n",
    "run_strategy() # call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from unsync import unsync\n",
    "\n",
    "# Initialize Kraken Pro Exchange\n",
    "exchange = ccxt.kraken({\n",
    "    'apiKey': 'your_api_key',\n",
    "    'secret': 'your_api_secret'\n",
    "})\n",
    "\n",
    "# Fetch the latest OHLCV data point (asynchronous)\n",
    "@unsync\n",
    "def fetch_latest_data(symbol, timeframe):\n",
    "    try:\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=1)\n",
    "        latest_data = ohlcv[-1]\n",
    "        return {\n",
    "            'timestamp': pd.to_datetime(latest_data[0], unit='ms'),\n",
    "            'open': latest_data[1],\n",
    "            'high': latest_data[2],\n",
    "            'low': latest_data[3],\n",
    "            'close': latest_data[4],\n",
    "            'volume': latest_data[5]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching latest data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Append new data to CSV and maintain max length (asynchronous)\n",
    "@unsync\n",
    "def append_to_csv_with_limit(data, filename, max_rows=3000):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    df = pd.DataFrame([data])\n",
    "    \n",
    "    if file_exists:\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        if len(combined_df) > max_rows:\n",
    "            combined_df = combined_df.iloc[-max_rows:]  # Keep only the last max_rows rows\n",
    "        combined_df.to_csv(filename, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "# Load the dataset from the CSV file (synchronous, needed for signal calculations)\n",
    "def load_data_from_csv(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Calculate moving averages on the dataset\n",
    "def calculate_moving_averages(df, fast_period, slow_period):\n",
    "    df['fast_ma'] = df['close'].rolling(window=fast_period).mean()\n",
    "    df['slow_ma'] = df['close'].rolling(window=slow_period).mean()\n",
    "    return df\n",
    "\n",
    "# Check crossover signals\n",
    "def check_crossover(df):\n",
    "    if len(df) < 2:\n",
    "        return None\n",
    "    if df['fast_ma'].iloc[-2] < df['slow_ma'].iloc[-2] and df['fast_ma'].iloc[-1] > df['slow_ma'].iloc[-1]:\n",
    "        return 'buy'\n",
    "    elif df['fast_ma'].iloc[-2] > df['slow_ma'].iloc[-2] and df['fast_ma'].iloc[-1] < df['slow_ma'].iloc[-1]:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_strategy_logic(symbol, timeframe, fast_period, slow_period, filename):\n",
    "    \"\"\"Executes the core strategy logic (fetching, appending, calculating, checking).\"\"\"\n",
    "    fetch_task = fetch_latest_data(symbol, timeframe)\n",
    "    latest_data = fetch_task.result()\n",
    "\n",
    "    if latest_data:\n",
    "        append_task = append_to_csv_with_limit(latest_data, filename)  # Use default max_rows\n",
    "        append_task.result()\n",
    "\n",
    "        dataset = load_data_from_csv(filename)\n",
    "        dataset = calculate_moving_averages(dataset, fast_period, slow_period)\n",
    "        signal = check_crossover(dataset)\n",
    "\n",
    "        if signal == 'buy':\n",
    "            print(f\"Buy signal detected at {latest_data['timestamp']}\")\n",
    "            # Place buy order logic here\n",
    "        elif signal == 'sell':\n",
    "            print(f\"Sell signal detected at {latest_data['timestamp']}\")\n",
    "            # Place sell order logic here\n",
    "        else:\n",
    "            print(f\"No signal at {latest_data['timestamp']}\")\n",
    "\n",
    "def run_hourly_strategy(symbol, timeframe, fast_period, slow_period, filename):\n",
    "    \"\"\"Runs the strategy hourly.\"\"\"\n",
    "\n",
    "    # Run the strategy logic immediately on startup\n",
    "    print(\"Running strategy on startup at:\", datetime.now())\n",
    "    run_strategy_logic(symbol, timeframe, fast_period, slow_period, filename)\n",
    "\n",
    "    while True:\n",
    "        now = datetime.now()\n",
    "        next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "        sleep_duration = (next_hour - now).total_seconds()\n",
    "        print(f\"Sleeping for {sleep_duration} seconds until the next hour...\")\n",
    "        time.sleep(sleep_duration)\n",
    "\n",
    "        print(\"Running strategy at:\", datetime.now())\n",
    "        run_strategy_logic(symbol, timeframe, fast_period, slow_period, filename)\n",
    "\n",
    "# Run the strategy\n",
    "\n",
    "symbol = 'BTC/USD'  # Trading pair\n",
    "timeframe = '1m'  # Timeframe\n",
    "fast_period = 5  # Fast moving average period\n",
    "slow_period = 20  # Slow moving average period\n",
    "csv_filename = 'market_data.csv'  # File to store historical data\n",
    "max_data_points = 3000  # Maximum number of rows in the CSV\n",
    "\n",
    "run_hourly_strategy(symbol, timeframe, fast_period, slow_period, csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Process:\n",
    "1. Ensure that we are trading every hour\n",
    "2. Get live data (3 Data points to account for the data preparation)\n",
    "3. Append it to csv, ensuring the limit of data points in the csv file (the limit == the train_size for the optimization process)\n",
    "4. Load the data from the csv file\n",
    "5. optimize if time to optimize (use optimize_counter)\n",
    "6. rebalance if time to rebalance (use rebalance_counter)\n",
    "7. Run the strategy on the dataset\n",
    "8. On the last time index (the last candle), get the universe (level 2 index) and actual allocation for each coin\\\n",
    "=> Make sure that we have applied self.live = True when initiating the strategy (to not shift the position values)\\\n",
    "(a) If coin not in universe -> Put their allocation\\\n",
    "(b) If actual allocation != shifted allocation, change the allocation of the coin\\\n",
    "--> Changing the allocation of a coin, is by determining the amount in currency = (amount_USD / close_price) to sell or to buy, then placing that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from unsync import unsync\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to exchange\n",
    "api_key = 'yqPWrtVuElaIExKmIp/E/upTOz/to1x7tC3JoFUxoSTKWCOorT6ifF/B'\n",
    "api_secret = 'L8h5vYoAu/jpQiBROA9yKN41FGwZAGGVF3nfrC5f5EiaoF7VksruPVdD7x1VOwnyyNCMdrGnT8lP4xHTiBrYMQ=='\n",
    "\n",
    "exchange = ccxt.kraken({\n",
    "    'apiKey': api_key,\n",
    "    'secret': api_secret\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC/USD', 'ETH/USD', 'LTC/USD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting symbols to a format that the exchange understands\n",
    "symbols = ['BTCUSD', 'ETHUSD', 'LTCUSD']\n",
    "formatted_symbol = [symbol.replace(\"USD\", \"/USD\") for symbol in symbols]\n",
    "formatted_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'error': [],\n",
       "  'result': {'XXBT': {'balance': '0.0000000000', 'hold_trade': '0.0000000000'},\n",
       "   'ZCAD': {'balance': '0.0000', 'hold_trade': '0.0000'},\n",
       "   'ZUSD': {'balance': '33.6557', 'hold_trade': '0.0000'}}},\n",
       " 'timestamp': None,\n",
       " 'datetime': None,\n",
       " 'BTC': {'free': 0.0, 'used': 0.0, 'total': 0.0},\n",
       " 'CAD': {'free': 0.0, 'used': 0.0, 'total': 0.0},\n",
       " 'USD': {'free': 33.6557, 'used': 0.0, 'total': 33.6557},\n",
       " 'free': {'BTC': 0.0, 'CAD': 0.0, 'USD': 33.6557},\n",
       " 'used': {'BTC': 0.0, 'CAD': 0.0, 'USD': 0.0},\n",
       " 'total': {'BTC': 0.0, 'CAD': 0.0, 'USD': 33.6557}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Account Portfolio operations\n",
    "balance = exchange.fetch_balance()\n",
    "balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.6557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance['total']['USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv = exchange.fetch_ohlcv('BTC/USD', '1h', limit=10)\n",
    "df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-11 13:00:00</th>\n",
       "      <td>94551.4</td>\n",
       "      <td>94551.9</td>\n",
       "      <td>94354.6</td>\n",
       "      <td>94356.8</td>\n",
       "      <td>10.062514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 14:00:00</th>\n",
       "      <td>94356.8</td>\n",
       "      <td>94549.1</td>\n",
       "      <td>94284.0</td>\n",
       "      <td>94548.3</td>\n",
       "      <td>5.791742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 15:00:00</th>\n",
       "      <td>94548.3</td>\n",
       "      <td>94580.0</td>\n",
       "      <td>94334.7</td>\n",
       "      <td>94359.3</td>\n",
       "      <td>19.460417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 16:00:00</th>\n",
       "      <td>94359.3</td>\n",
       "      <td>94665.5</td>\n",
       "      <td>94330.1</td>\n",
       "      <td>94391.2</td>\n",
       "      <td>7.116978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 17:00:00</th>\n",
       "      <td>94401.8</td>\n",
       "      <td>94401.8</td>\n",
       "      <td>93919.0</td>\n",
       "      <td>94104.2</td>\n",
       "      <td>19.314240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 18:00:00</th>\n",
       "      <td>94104.2</td>\n",
       "      <td>94257.0</td>\n",
       "      <td>94075.0</td>\n",
       "      <td>94244.1</td>\n",
       "      <td>32.384815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 19:00:00</th>\n",
       "      <td>94244.1</td>\n",
       "      <td>94281.3</td>\n",
       "      <td>94007.6</td>\n",
       "      <td>94187.5</td>\n",
       "      <td>6.698506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 20:00:00</th>\n",
       "      <td>94187.5</td>\n",
       "      <td>94597.4</td>\n",
       "      <td>94160.4</td>\n",
       "      <td>94567.7</td>\n",
       "      <td>13.310514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 21:00:00</th>\n",
       "      <td>94567.7</td>\n",
       "      <td>94986.6</td>\n",
       "      <td>94530.1</td>\n",
       "      <td>94921.6</td>\n",
       "      <td>65.167654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close     volume\n",
       "timestamp                                                         \n",
       "2025-01-11 13:00:00  94551.4  94551.9  94354.6  94356.8  10.062514\n",
       "2025-01-11 14:00:00  94356.8  94549.1  94284.0  94548.3   5.791742\n",
       "2025-01-11 15:00:00  94548.3  94580.0  94334.7  94359.3  19.460417\n",
       "2025-01-11 16:00:00  94359.3  94665.5  94330.1  94391.2   7.116978\n",
       "2025-01-11 17:00:00  94401.8  94401.8  93919.0  94104.2  19.314240\n",
       "2025-01-11 18:00:00  94104.2  94257.0  94075.0  94244.1  32.384815\n",
       "2025-01-11 19:00:00  94244.1  94281.3  94007.6  94187.5   6.698506\n",
       "2025-01-11 20:00:00  94187.5  94597.4  94160.4  94567.7  13.310514\n",
       "2025-01-11 21:00:00  94567.7  94986.6  94530.1  94921.6  65.167654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest data:                         open     high      low    close     volume\n",
      "timestamp                                                         \n",
      "2025-01-11 20:00:00  94187.5  94597.4  94160.4  94567.7  13.310514\n",
      "2025-01-11 21:00:00  94567.7  94986.6  94530.1  94921.6  65.167654\n"
     ]
    }
   ],
   "source": [
    "@unsync\n",
    "def fetch_latest_data(symbol, timeframe):\n",
    "    try:\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=3)\n",
    "        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "        latest_data = df[:-1]\n",
    "        return latest_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching latest data: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Fetch the latest OHLCV data point (asynchronous)\n",
    "try:\n",
    "    latest = fetch_latest_data('BTC/USD', '1h')\n",
    "    latest.result()\n",
    "    print('latest data:', latest.result())\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching latest data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-11 20:00:00</th>\n",
       "      <td>94187.5</td>\n",
       "      <td>94597.4</td>\n",
       "      <td>94160.4</td>\n",
       "      <td>94567.7</td>\n",
       "      <td>13.310514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-11 21:00:00</th>\n",
       "      <td>94567.7</td>\n",
       "      <td>94986.6</td>\n",
       "      <td>94530.1</td>\n",
       "      <td>94921.6</td>\n",
       "      <td>65.167654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close     volume\n",
       "timestamp                                                         \n",
       "2025-01-11 20:00:00  94187.5  94597.4  94160.4  94567.7  13.310514\n",
       "2025-01-11 21:00:00  94567.7  94986.6  94530.1  94921.6  65.167654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unsync\n",
    "def fetch_latest_data(symbols, timeframe, limit = 2):\n",
    "    \"\"\"Fetch latest OHLCV data for multiple symbols and stack them into a single DataFrame.\"\"\"\n",
    "    data_frames = []\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            # Fetch OHLCV data\n",
    "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)\n",
    "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "            \n",
    "            # Convert timestamp to datetime\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "            \n",
    "            # Add a symbol column\n",
    "            df['coin'] = symbol\n",
    "            data_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol}: {e}\")\n",
    "    \n",
    "    # Concatenate all DataFrames and set multi-level index\n",
    "    if data_frames:\n",
    "        stacked_df = pd.concat(data_frames)\n",
    "        stacked_df.set_index('coin', append=True, inplace=True)\n",
    "        # Remove duplicates from the index\n",
    "        stacked_df = stacked_df[~stacked_df.index.duplicated()]\n",
    "        df = data_instance.prepare_data(stacked_df.unstack())\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data\n",
    "\n",
    "# Example usage\n",
    "timeframe = '1h'\n",
    "latest = fetch_latest_data(symbols, timeframe)\n",
    "latest.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94921.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest.result()['close'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order placed successfully: {'id': 'O23OWI-A2ULZ-BWA3VH', 'clientOrderId': None, 'info': {'txid': ['O23OWI-A2ULZ-BWA3VH'], 'descr': {'order': 'buy 0.00036295 XBTUSD @ limit 94187.5'}}, 'timestamp': None, 'datetime': None, 'lastTradeTimestamp': None, 'status': None, 'symbol': 'BTC/USD', 'type': 'limit', 'timeInForce': None, 'postOnly': False, 'side': 'buy', 'price': 94187.5, 'stopPrice': None, 'triggerPrice': None, 'takeProfitPrice': None, 'stopLossPrice': None, 'cost': None, 'amount': 0.00036295, 'filled': None, 'average': None, 'remaining': None, 'reduceOnly': None, 'fee': None, 'trades': [], 'fees': [], 'lastUpdateTimestamp': None}\n"
     ]
    }
   ],
   "source": [
    "#Placing a limit order\n",
    "symbol = \"BTC/USD\"  # Trading pair\n",
    "order_type = \"limit\"  # Order type: limit or market\n",
    "side = \"buy\"  # Order side: buy or sell\n",
    "amount = balance['total']['USD'] / latest.result()['close'].iloc[-1]  # Amount in BTC\n",
    "price = latest.result()['close'].iloc[-1] # Limit price in USD\n",
    "\n",
    "try:\n",
    "    order = exchange.create_order(symbol, order_type, side, amount, price)\n",
    "    print(\"Order placed successfully:\", order)\n",
    "except Exception as e:\n",
    "    print(f\"Error placing order: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fetch open orders\n",
    "try:\n",
    "    # Fetch open orders\n",
    "    open_orders = exchange.fetch_open_orders()\n",
    "    for order in open_orders:\n",
    "        print(f\"Order ID: {order['id']}, Symbol: {order['symbol']}, Amount: {order['amount']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching open orders: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order canceled successfully: {'info': {'error': [], 'result': {'count': '1'}}, 'fees': [], 'id': None, 'clientOrderId': None, 'timestamp': None, 'datetime': None, 'symbol': None, 'type': None, 'side': None, 'lastTradeTimestamp': None, 'lastUpdateTimestamp': None, 'price': None, 'amount': None, 'cost': None, 'average': None, 'filled': None, 'remaining': None, 'timeInForce': None, 'postOnly': None, 'trades': [], 'reduceOnly': None, 'stopPrice': None, 'triggerPrice': None, 'takeProfitPrice': None, 'stopLossPrice': None, 'status': None, 'fee': None}\n"
     ]
    }
   ],
   "source": [
    "#To cancel an order\n",
    "try:\n",
    "    order_id = \"O23OWI-A2ULZ-BWA3VH\"  # Replace with the actual order ID\n",
    "    cancel_response = exchange.cancel_order(order_id)\n",
    "    print(f\"Order canceled successfully: {cancel_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error canceling order: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current price of BTC/USD: 92222.1\n"
     ]
    }
   ],
   "source": [
    "symbol = \"BTC/USD\"  # Replace with your desired symbol\n",
    "try:\n",
    "    # Specify the ticker symbol\n",
    "    ticker = exchange.fetch_ticker(symbol)\n",
    "    \n",
    "    # Get the current price\n",
    "    current_price = ticker['last']  # 'last' is the latest trade price\n",
    "    print(f\"Current price of {symbol}: {current_price}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching ticker data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market order placed successfully: {'id': 'ORBCS3-XUKDQ-KIXTK4', 'clientOrderId': None, 'info': {'txid': ['ORBCS3-XUKDQ-KIXTK4'], 'descr': {'order': 'buy 0.00036494 XBTUSD @ market'}}, 'timestamp': None, 'datetime': None, 'lastTradeTimestamp': None, 'status': None, 'symbol': 'BTC/USD', 'type': 'market', 'timeInForce': 'IOC', 'postOnly': False, 'side': 'buy', 'price': None, 'stopPrice': None, 'triggerPrice': None, 'takeProfitPrice': None, 'stopLossPrice': None, 'cost': None, 'amount': 0.00036494, 'filled': None, 'average': None, 'remaining': None, 'reduceOnly': None, 'fee': None, 'trades': [], 'fees': [], 'lastUpdateTimestamp': None}\n"
     ]
    }
   ],
   "source": [
    "# Placing a buy order and a sell order\n",
    "order_type = \"market\"  # Market order\n",
    "symbol = \"BTC/USD\"  # Trading pair\n",
    "side = \"buy\"  # Order side: buy or sell\n",
    "amount = balance['total']['USD'] / current_price  # Amount in BTC\n",
    "\n",
    "try:\n",
    "    order = exchange.create_order(symbol, order_type, side, amount)\n",
    "    print(\"Market order placed successfully:\", order)\n",
    "except Exception as e:\n",
    "    print(f\"Error placing market order: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_trade = [symbol.replace(\"/USD\", \"\") for symbol in formatted_symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC', 'ETH', 'LTC']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_to_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance = exchange.fetch_balance()\n",
    "balance['total'][symbols_to_trade[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'error': [],\n",
       "  'result': {'XXBT': {'balance': '0.0000000000', 'hold_trade': '0.0000000000'},\n",
       "   'ZCAD': {'balance': '0.0000', 'hold_trade': '0.0000'},\n",
       "   'ZUSD': {'balance': '33.6557', 'hold_trade': '0.0000'}}},\n",
       " 'timestamp': None,\n",
       " 'datetime': None,\n",
       " 'BTC': {'free': 0.0, 'used': 0.0, 'total': 0.0},\n",
       " 'CAD': {'free': 0.0, 'used': 0.0, 'total': 0.0},\n",
       " 'USD': {'free': 33.6557, 'used': 0.0, 'total': 33.6557},\n",
       " 'free': {'BTC': 0.0, 'CAD': 0.0, 'USD': 33.6557},\n",
       " 'used': {'BTC': 0.0, 'CAD': 0.0, 'USD': 0.0},\n",
       " 'total': {'BTC': 0.0, 'CAD': 0.0, 'USD': 33.6557}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available BTC: 0.0\n",
      "No BTC available to sell.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Step 1: Check your balance\n",
    "    balance = exchange.fetch_balance()\n",
    "    coin = \"BTC\"  # Replace with the coin you want to sell\n",
    "    amount = balance[coin][\"free\"]  # Amount available to sell\n",
    "    print(f\"Available {coin}: {amount}\")\n",
    "\n",
    "    if amount > 0:\n",
    "        # Step 2: Place a market sell order\n",
    "        symbol = formatted_symbol[0]  # Replace USD with your desired quote currency\n",
    "        order = exchange.create_market_sell_order(symbol, amount)\n",
    "        print(f\"Sell order placed: {order}\")\n",
    "    else:\n",
    "        print(f\"No {coin} available to sell.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hourly_strategy(symbol, timeframe, fast_period, slow_period, filename):\n",
    "    \"\"\"Runs the strategy hourly.\"\"\"\n",
    "\n",
    "    # Run the strategy logic immediately on startup\n",
    "    print(\"Running strategy on startup at:\", datetime.now())\n",
    "    # run_strategy_logic(symbol, timeframe, fast_period, slow_period, filename)\n",
    "\n",
    "    while True:\n",
    "        now = datetime.now()\n",
    "        next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "        print(f\"Next hour: {next_hour}\")\n",
    "        sleep_duration = (next_hour - now).total_seconds()\n",
    "        print(f\"Sleeping for {sleep_duration} seconds until the next hour...\")\n",
    "        time.sleep(sleep_duration)\n",
    "\n",
    "        print(\"Running strategy at:\", datetime.now())\n",
    "        # run_strategy_logic(symbol, timeframe, fast_period, slow_period, filename)\n",
    "        \n",
    "symbol = 'BTC/USD'  # Trading pair\n",
    "timeframe = '1m'  # Timeframe\n",
    "fast_period = 5  # Fast moving average period\n",
    "slow_period = 20  # Slow moving average period\n",
    "csv_filename = 'market_data.csv'  # File to store historical data\n",
    "max_data_points = 3000  # Maximum number of rows in the CSV\n",
    "\n",
    "run_hourly_strategy(symbol, timeframe, fast_period, slow_period, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BTC to sell.\n",
      "No CAD to sell.\n",
      "Selling 33.6557 USD...\n",
      "Error: kraken does not have market symbol USD/USD\n"
     ]
    }
   ],
   "source": [
    "#To liquidate everything:\n",
    "try:\n",
    "    # Step 1: Get your balances\n",
    "    balance = exchange.fetch_balance()\n",
    "    \n",
    "    # Step 2: Loop through all assets in your balance and sell them\n",
    "    for coin, coin_balance in balance['free'].items():\n",
    "        if coin_balance > 0:  # Only sell if you have a non-zero balance\n",
    "            print(f\"Selling {coin_balance} {coin}...\")\n",
    "            \n",
    "            # Determine the symbol for the sell order (e.g., BTC/USD, ETH/USDT)\n",
    "            symbol = f\"{coin}/USD\"  # Replace USD with your preferred quote currency\n",
    "            order = exchange.create_market_sell_order(symbol, coin_balance)\n",
    "            print(f\"Sell order placed: {order}\")\n",
    "        else:\n",
    "            print(f\"No {coin} to sell.\")\n",
    "    \n",
    "    print(\"All possible assets have been liquidated.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liquidate(symbols, exchange):\n",
    "    try:\n",
    "        # Step 1: Get your balances\n",
    "        balance = exchange.fetch_balance()\n",
    "\n",
    "        # Step 2: Loop through all assets in your balance and sell them\n",
    "        for coin, coin_balance in balance['free'].items():\n",
    "            if coin in symbols:\n",
    "                if coin_balance > 0:  # Only sell if you have a non-zero balance\n",
    "                    print(f\"Selling {coin_balance} {coin}...\")\n",
    "\n",
    "                    # Determine the symbol for the sell order (e.g., BTC/USD, ETH/USDT)\n",
    "                    symbol = f\"{coin}/USD\"  # Replace USD with your preferred quote currency\n",
    "                    order = exchange.create_market_sell_order(symbol, coin_balance)\n",
    "                    print(f\"Sell order placed: {order}\")\n",
    "                else:\n",
    "                    print(f\"No {coin} to sell.\")\n",
    "\n",
    "        print(\"All possible assets have been liquidated.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode:\n",
    "\n",
    "```(Python)\n",
    "#in the hourly function loop\n",
    "self.counter_opt = 0\n",
    "self.counter_reb = 0\n",
    "self.strats_map = {...}\n",
    "self.selected_strats = {...}\n",
    "self.weights = []\n",
    "self.best_params = {}\n",
    "\n",
    "run_strategy():\n",
    "    opt_interval = strat.train_size\n",
    "    reb_interval = 236 #nbr of hours in each 2 weeks\n",
    "\n",
    "\n",
    "    latest = fetch_last_data()\\\n",
    "    latest.result()\n",
    "\n",
    "    if latest:\n",
    "        append = append_to_csv(latest)\n",
    "        append.result() #Because we are going to be using the unsync the library\n",
    "\n",
    "        data = load_data_from_csv()\n",
    "\n",
    "        if self.counter_opt % opt_interval == 0 and len(data) >= opt_interval:\n",
    "            self.best_params = [strat.optimize() for strat in self.strats_map]\n",
    "\n",
    "        \n",
    "        self.opt_counter += 1\n",
    "        self.reb_counter += 1\n",
    "\n",
    "        df_strats = [\n",
    "        strat(self.best_params[i])\n",
    "        for i in range(len(self.best_params))  # Iterate over indices\n",
    "        for strat in self.selected_strats.values()  # Iterate over strategies\n",
    "        ]\n",
    "\n",
    "        if self.counter_reb % reb_interval == 0 and len(data) >= reb_interval:\n",
    "            log_rets = [strat.trading_strategy(data, self.best_params).results.strategy for strat in self.selected_strats.values()]\n",
    "            self.selected_strats = portfolio_management(strat_map) -> {}\n",
    "            weights = portfolio_optimization(log_rets, ...).optimize(data) -> []\n",
    "            portfolio_value = exchange.... #the current portfolio value of the account\n",
    "            max_allocation_per_strat_list = weights * list -> []\n",
    "            self.max_allocation_per_strat_map = dict(zip(self.selected_strats.keys(), max_allocation_per_strat_list))\n",
    "\n",
    "        #actual_allocation in coin currency\n",
    "        for i in range(df_strats):\n",
    "            df['actual_allocation_coin_currency'] = df['actual_allocation']  / df['close']\n",
    "\n",
    "        current_universes= [df_strats[i].index.get_level_values(1).unique() for i in range(df_strats)]\n",
    "\n",
    "        # Flatten into 1D list\n",
    "        current_universe = []\n",
    "        for sublist in two_d_list:\n",
    "            for item in sublist:\n",
    "                current_universe.append(item) if item not in current_universe\n",
    "            \n",
    "        current_coins = exchange.... #Current coins in the account portfolio\n",
    "\n",
    "        for coin in current_coins\n",
    "            if coin not in current_universe:\n",
    "                #liquidate those coins\n",
    "\n",
    "        coins_allocations = sum(df_strats['actual_allocation_coin_currency']).iloc[-1]\n",
    "\n",
    "        for coin in current_universe:\n",
    "            current_position = exchange.... -> float()\n",
    "            actual_allocation = coins_allocation.unstack().coin -> float()\n",
    "\n",
    "            to_add = current_position - actual_allocation\n",
    "\n",
    "            if to_add > 0:\n",
    "                #place a buy order of that quantity for that coin\n",
    "            if to_add < 0:\n",
    "                #place a sell order of that quantity for that coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from unsync import unsync\n",
    "import datetime as dt\n",
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directories are in the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'Data_Management'))) \n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'Portfolio_Optimization'))) \n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'Strategies', 'Trend_Following')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'Strategies', 'Mean_Reversion')))\n",
    "\n",
    "# Import the modules\n",
    "from data import Data, get_halal_symbols\n",
    "from fetch_symbols import get_symbols\n",
    "from sprtrnd_breakout import Sprtrnd_Breakout\n",
    "from last_days_low import Last_Days_Low\n",
    "from portfolio_management import Portfolio_Management\n",
    "from portfolio_optimization import Portfolio_Optimization\n",
    "from portfolio_risk_management import Portfolio_RM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to exchange\n",
    "api_key = 'yqPWrtVuElaIExKmIp/E/upTOz/to1x7tC3JoFUxoSTKWCOorT6ifF/B'\n",
    "api_secret = 'L8h5vYoAu/jpQiBROA9yKN41FGwZAGGVF3nfrC5f5EiaoF7VksruPVdD7x1VOwnyyNCMdrGnT8lP4xHTiBrYMQ=='\n",
    "\n",
    "exchange = ccxt.kraken({\n",
    "    'apiKey': api_key,\n",
    "    'secret': api_secret\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symbols = get_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 2201\n",
    "test_size = 2201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n",
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n",
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n",
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n",
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n",
      "c:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Data_Management\\data.py:104: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  _df['returns', coin] = _df['close', coin].pct_change()\n"
     ]
    }
   ],
   "source": [
    "start_time = (dt.datetime.now() - dt.timedelta(hours=train_size + test_size + 200)).date()\n",
    "end_time = dt.datetime.now().date()\n",
    "timeframes = ['1w', '1d', '4h', '1h', '30m','15m', '5m', '1m']\n",
    "index = 3 #It is better to choose the highest frequency for the backtest to be able to downsample\n",
    "interval = timeframes[index]\n",
    "symbols = ['BTCUSD', 'ETHUSD', 'BNBUSD', 'ADAUSD', 'XRPUSD']\n",
    "data_instance = Data(all_symbols, interval, start_time, end_time, exchange = 'kraken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_instance.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date_data = data.index.get_level_values(0).unique()[-1].tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_symbols = format_symbols(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dt.datetime.now(dt.UTC).replace(minute=0, second=0, microsecond=0) != last_date_data:\n",
    "    time_difference = dt.datetime.now(dt.UTC).replace(minute=0, second=0, microsecond=0) - last_date_data\n",
    "    hours_difference = time_difference.total_seconds() / 3600 # Get the number of hours\n",
    "    missing_data = fetch_latest_data(formatted_symbols, interval, limit = int(hours_difference) + 2).result()\n",
    "    complete_data = pd.concat([data, missing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.index = complete_data.index.set_levels(pd.to_datetime(complete_data.index.levels[0]), level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.to_csv('market_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_market_data(halal_symbols, train_size = 2200, test_size = 2200):\n",
    "    start_time = (dt.datetime.now() - dt.timedelta(hours=train_size + test_size + 200)).date()\n",
    "    end_time = dt.datetime.now().date()\n",
    "    timeframes = ['1w', '1d', '4h', '1h', '30m','15m', '5m', '1m']\n",
    "    index = 3 #It is better to choose the highest frequency for the backtest to be able to downsample\n",
    "    interval = timeframes[index]\n",
    "    data_instance = Data(halal_symbols, interval, start_time, end_time, exchange = 'kraken')\n",
    "    data = data_instance.df\n",
    "    last_date_data = data.index.get_level_values(0).unique()[-1].tz_localize('UTC')\n",
    "    formatted_symbols = format_symbols(halal_symbols)\n",
    "    \n",
    "    if dt.datetime.now(dt.UTC).replace(minute=0, second=0, microsecond=0) != last_date_data:\n",
    "        time_difference = dt.datetime.now(dt.UTC).replace(minute=0, second=0, microsecond=0) - last_date_data\n",
    "        hours_difference = time_difference.total_seconds() / 3600 # Get the number of hours\n",
    "        missing_data = fetch_latest_data(formatted_symbols, interval, limit = int(hours_difference) + 2).result()\n",
    "        complete_data = pd.concat([data, missing_data])\n",
    "        \n",
    "    complete_data.index = complete_data.index.set_levels(pd.to_datetime(complete_data.index.levels[0]), level=0)\n",
    "    complete_data.to_csv('market_data.csv')\n",
    "    print('Market data updated successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At each time we loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function\n",
    "def get_last_row(data):\n",
    "    \"\"\"Get the last date in the dataset.\"\"\"\n",
    "    last_date = data.index.get_level_values(\"date\").max()\n",
    "    last_date_data = data.loc[last_date]\n",
    "    return last_date_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portfolio_value(exchange):\n",
    "    try:\n",
    "        # Fetch account balances\n",
    "        balances = exchange.fetch_balance()\n",
    "\n",
    "        # Fetch tickers to get the latest prices\n",
    "        tickers = exchange.fetch_tickers()\n",
    "\n",
    "        # Calculate portfolio value in USD (or another base currency)\n",
    "        portfolio_value = 0.0\n",
    "\n",
    "        for currency, balance in balances['total'].items():\n",
    "            if balance > 0:\n",
    "                # Use the USD pair or the most liquid market\n",
    "                pair = f\"{currency}/USD\"\n",
    "                if pair in tickers:\n",
    "                    price = tickers[pair]['last']\n",
    "                    portfolio_value += balance * price\n",
    "                else:\n",
    "                    # Handle currencies without USD pairs (e.g., trade to BTC, then USD)\n",
    "                    btc_pair = f\"{currency}/BTC\"\n",
    "                    if btc_pair in tickers:\n",
    "                        btc_price = tickers[btc_pair]['last']\n",
    "                        usd_price = tickers[\"BTC/USD\"]['last']\n",
    "                        portfolio_value += balance * btc_price * usd_price\n",
    "\n",
    "        return portfolio_value\n",
    "\n",
    "    except ccxt.BaseError as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_value = get_portfolio_value(exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.38000406"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_symbols(symbols):\n",
    "    \"\"\"Converts the symbols to a format that the exchange understands.\"\"\"\n",
    "    if symbols[0].endswith('T'):\n",
    "        symbols = [s[:-1] for s in symbols]\n",
    "    formatted_symbols = [symbol.replace(\"USD\", \"/USD\") for symbol in symbols]\n",
    "    return formatted_symbols\n",
    "\n",
    "def filter_halal_df(data):\n",
    "    # Drop multiple coins\n",
    "    halal_symbols = ['BTC/USD', 'ETH/USD', 'LTC/USD']\n",
    "    data_filtered = data[data.index.get_level_values(\"coin\").isin(halal_symbols)]\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halal_symbols = get_halal_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_halal_symbols = format_symbols(halal_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unsync\n",
    "def fetch_latest_data(symbols, timeframe, limit=2):\n",
    "    \"\"\"Fetch latest OHLCV data for multiple symbols and stack them into a single DataFrame.\"\"\"\n",
    "    \n",
    "    def fetch_symbol_data(symbol):\n",
    "        \"\"\"Fetch data for a single symbol and return a DataFrame.\"\"\"\n",
    "        try:\n",
    "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)\n",
    "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "            df['coin'] = symbol\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if fetching fails\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel requests\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:  # Adjust workers based on CPU\n",
    "        results = list(executor.map(fetch_symbol_data, symbols))\n",
    "\n",
    "    # Concatenate all DataFrames and set multi-level index\n",
    "    data_frames = [df for df in results if not df.empty]\n",
    "    if data_frames:\n",
    "        stacked_df = pd.concat(data_frames)\n",
    "        stacked_df.set_index('coin', append=True, inplace=True)\n",
    "        stacked_df = stacked_df[~stacked_df.index.duplicated()]  # Remove duplicates\n",
    "        df = data_instance.prepare_data(stacked_df.unstack())\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data\n",
    "\n",
    "# Example usage\n",
    "timeframe = '1h'\n",
    "latest = fetch_latest_data(formatted_symbols, timeframe)\n",
    "sample_data = latest.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>creturns</th>\n",
       "      <th>high</th>\n",
       "      <th>log_return</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>price</th>\n",
       "      <th>returns</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_in_dollars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>coin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2025-01-13 19:00:00</th>\n",
       "      <th>ADA/USD</th>\n",
       "      <td>0.912936</td>\n",
       "      <td>1.005705</td>\n",
       "      <td>0.917609</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.903511</td>\n",
       "      <td>0.906877</td>\n",
       "      <td>0.912936</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>7.747882e+05</td>\n",
       "      <td>7.073320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BTC/USD</th>\n",
       "      <td>92090.700000</td>\n",
       "      <td>1.000700</td>\n",
       "      <td>92442.900000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>91605.400000</td>\n",
       "      <td>92026.300000</td>\n",
       "      <td>92090.700000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.590086e+01</td>\n",
       "      <td>4.227043e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETH/USD</th>\n",
       "      <td>3022.840000</td>\n",
       "      <td>1.005191</td>\n",
       "      <td>3034.570000</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>2992.410000</td>\n",
       "      <td>3007.230000</td>\n",
       "      <td>3022.840000</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>2.572654e+02</td>\n",
       "      <td>7.776721e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRP/USD</th>\n",
       "      <td>2.464430</td>\n",
       "      <td>1.006391</td>\n",
       "      <td>2.480670</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>2.438000</td>\n",
       "      <td>2.448960</td>\n",
       "      <td>2.464430</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>2.154674e+06</td>\n",
       "      <td>5.310042e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    close  creturns          high  log_return  \\\n",
       "date                coin                                                        \n",
       "2025-01-13 19:00:00 ADA/USD      0.912936  1.005705      0.917609    0.005689   \n",
       "                    BTC/USD  92090.700000  1.000700  92442.900000    0.000700   \n",
       "                    ETH/USD   3022.840000  1.005191   3034.570000    0.005177   \n",
       "                    XRP/USD      2.464430  1.006391      2.480670    0.006371   \n",
       "\n",
       "                                      low          open         price  \\\n",
       "date                coin                                                \n",
       "2025-01-13 19:00:00 ADA/USD      0.903511      0.906877      0.912936   \n",
       "                    BTC/USD  91605.400000  92026.300000  92090.700000   \n",
       "                    ETH/USD   2992.410000   3007.230000   3022.840000   \n",
       "                    XRP/USD      2.438000      2.448960      2.464430   \n",
       "\n",
       "                              returns        volume  volume_in_dollars  \n",
       "date                coin                                                \n",
       "2025-01-13 19:00:00 ADA/USD  0.005705  7.747882e+05       7.073320e+05  \n",
       "                    BTC/USD  0.000700  4.590086e+01       4.227043e+06  \n",
       "                    ETH/USD  0.005191  2.572654e+02       7.776721e+05  \n",
       "                    XRP/USD  0.006391  2.154674e+06       5.310042e+06  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new data to CSV and maintain max length (asynchronous)\n",
    "@unsync\n",
    "def append_to_csv_with_limit(data, filename, max_rows=2202):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if file_exists:\n",
    "        existing_df = pd.read_csv(filename, index_col=['date', 'coin'], parse_dates=['date'])\n",
    "        combined_df = pd.concat([existing_df, df])\n",
    "        if len(combined_df) > max_rows:\n",
    "            combined_df = combined_df.iloc[-max_rows:]  # Keep only the last max_rows rows\n",
    "        combined_df.to_csv(filename)\n",
    "    else:\n",
    "        print('File does not exist')\n",
    "        df.to_csv(filename, mode='w', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data from csv\n",
    "def load_data_from_csv(filename, train_size = 2000, test_size = 2000):\n",
    "    if os.path.isfile(filename):\n",
    "        data = pd.read_csv(filename, index_col=['date', 'coin'], parse_dates=['date'])\n",
    "        if len(data) >= train_size + test_size:\n",
    "            return data\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_from_csv('market_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be ran every time we want to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_strat_1 = Last_Days_Low(data, objective = 'multiple')\n",
    "tf_strat_1 = Sprtrnd_Breakout(data, objective = 'multiple')\n",
    "\n",
    "#Create a dummy results that represents holding cash where the value of the portfolio is constant\n",
    "cash_df = pd.DataFrame(data = {'strategy': np.zeros(data.shape[0]), 'portfolio_value': np.ones(data.shape[0])}, index = data.index)\n",
    "\n",
    "strategy_map = {'cash_strat': cash_df,\n",
    "                'mr_strat_1': mr_strat_1,\n",
    "                'tf_strat_1': tf_strat_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('stop_loss', 'AAVEUSDT')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\multi.py:3053\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:776\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2152\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2176\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 7170",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m strategy_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcash_strat\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Strategies\\Mean_Reversion\\last_days_low.py:310\u001b[0m, in \u001b[0;36mLast_Days_Low.test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03mTest the strategy using the best parameters from the optimization\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m \n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    300\u001b[0m wfo \u001b[38;5;241m=\u001b[39m WFO(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf, \n\u001b[0;32m    301\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrading_strategy, \n\u001b[0;32m    302\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m             objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective, \n\u001b[0;32m    308\u001b[0m             opt_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_freq)\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperformance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mwfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk_forward_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcum_strategy \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_universe))\u001b[38;5;241m.\u001b[39mcumsum()\u001b[38;5;241m.\u001b[39mapply(np\u001b[38;5;241m.\u001b[39mexp)\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Validation\\testing.py:277\u001b[0m, in \u001b[0;36mWFO.walk_forward_optimization\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_parameters_grid(train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 277\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_parameters_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Test on out-of-sample data\u001b[39;00m\n\u001b[0;32m    280\u001b[0m performance, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_strategy(test, best_params)\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Validation\\testing.py:244\u001b[0m, in \u001b[0;36mWFO.optimize_parameters_gp\u001b[1;34m(self, train_data, param_space)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mobjective \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(objective) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1e10\u001b[39m  \u001b[38;5;66;03m# Handle invalid values\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Run gp_minimize\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of evaluations\u001b[39;49;00m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Extract the best parameters\u001b[39;00m\n\u001b[0;32m    252\u001b[0m best_params \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: val \u001b[38;5;28;01mfor\u001b[39;00m dim, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_space, result\u001b[38;5;241m.\u001b[39mx)}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[0;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[0;32m    279\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\skopt\\optimizer\\base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[0;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[1;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[0;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Validation\\testing.py:237\u001b[0m, in \u001b[0;36mWFO.optimize_parameters_gp.<locals>.objective\u001b[1;34m(param_space)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(param_space):\n\u001b[1;32m--> 237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrading_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Use negative performance because gp_minimize minimizes\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_function(result) \n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Strategies\\Mean_Reversion\\last_days_low.py:223\u001b[0m, in \u001b[0;36mLast_Days_Low.trading_strategy\u001b[1;34m(self, data, params, std_window, mean_window, ema_window, hourly_lookback, daily_lookback, _min_pos, _max_pos, sl_ind_length, sl_ind_mult, tp_mult, ptp_mult, ptp_exit_percent, low_freq_index, high_freq_index, max_perc_risk, max_dollar_allocation, sl_type, tp_type, sl_signal_only, tp_signal_only, ptp_signal_only, tp_ind_length, fixed_sl, fixed_tp, maker, taker)\u001b[0m\n\u001b[0;32m    221\u001b[0m _df \u001b[38;5;241m=\u001b[39m pos\u001b[38;5;241m.\u001b[39minitialize_position()\n\u001b[0;32m    222\u001b[0m sl \u001b[38;5;241m=\u001b[39m Stop_Loss(_df, sl_type, sl_ind_length, sl_ind_mult, sl_signal_only)\n\u001b[1;32m--> 223\u001b[0m _df \u001b[38;5;241m=\u001b[39m \u001b[43msl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_stop_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_sl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m tp \u001b[38;5;241m=\u001b[39m Take_Profit(_df, tp_type, tp_mult, tp_signal_only)\n\u001b[0;32m    225\u001b[0m _df \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mapply_take_profit(fixed_tp, plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Risk_Management\\tail_risk.py:253\u001b[0m, in \u001b[0;36mStop_Loss.apply_stop_loss\u001b[1;34m(self, fixed, plot)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_stop_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, fixed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    This function applies the stop loss to the dataframe and calculates the trades, strategy returns, strategy cumulative returns, and sessions.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    it acts as a wrapper for the calculate_fixed_sl function, and make the necessary adjustments after that position column has changed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m            This is essential if we are using sl_type of percent or dollar.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m     _df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_fixed_sl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m fixed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_dynamic_sl()\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_sl(_df)\n",
      "File \u001b[1;32mc:\\Users\\yassi\\OneDrive\\Documents\\GitHub\\Portfolio_1\\Technical_Portfolio\\Risk_Management\\tail_risk.py:174\u001b[0m, in \u001b[0;36mStop_Loss.calculate_fixed_sl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m#Calculate the session stop loss\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coin \u001b[38;5;129;01min\u001b[39;00m _df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mlevels[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 174\u001b[0m     _df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_stop_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, coin] \u001b[38;5;241m=\u001b[39m \u001b[43m_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoin\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m, coin])\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# Group by both the session and coin, then pass the coin as an additional argument\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_only:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[1;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\multi.py:3055\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3057\u001b[0m     \u001b[38;5;66;03m# e.g. test_partial_slicing_with_multiindex partial string slicing\u001b[39;00m\n\u001b[0;32m   3058\u001b[0m     loc, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loc_level(key, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)))\n",
      "\u001b[1;31mKeyError\u001b[0m: ('stop_loss', 'AAVEUSDT')"
     ]
    }
   ],
   "source": [
    "#Run the WFO for each strategy (but the cash strategy)\n",
    "for key, value in strategy_map.items():\n",
    "    if key != 'cash_strat':\n",
    "        value.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new dictionary that contains the results strategy returns of the WFO\n",
    "results_strategy_returns = {}\n",
    "for key, value in strategy_map.items():\n",
    "    if key != 'cash_strat':\n",
    "        results_strategy_returns[key] = value.results.strategy\n",
    "    elif key == 'cash_strat':\n",
    "        results_strategy_returns[key] = value.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_management = Portfolio_Management(results_strategy_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_selected_strategy = portfolio_management.filter_by_correlation().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_strategy = {key: value for key, value in strategy_map.items() if key in keys_for_selected_strategy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_opt = 0\n",
    "counter_reb = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the optimization to get the strategy parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
