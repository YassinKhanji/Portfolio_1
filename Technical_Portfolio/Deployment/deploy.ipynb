{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "1. Ensure that we are trading every hour\n",
    "2. Get live data (3 Data points to account for the data preparation)\n",
    "3. Append it to csv, ensuring the limit of data points in the csv file (the limit == the train_size for the optimization process)\n",
    "4. Load the data from the csv file\n",
    "5. optimize if time to optimize\n",
    "6. rebalance if time to rebalance\n",
    "7. Run the strategy on the dataset\n",
    "8. on the last time index (the last candle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def run_strategy():\n",
    "    while True:\n",
    "        # Get current time and calculate next hour\n",
    "        now = datetime.now()\n",
    "        next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "        \n",
    "        # Wait until the next hour\n",
    "        sleep_duration = (next_hour - now).total_seconds()\n",
    "        print(f\"Sleeping for {sleep_duration} seconds...\")\n",
    "        time.sleep(sleep_duration)\n",
    "        \n",
    "        # Execute your strategy\n",
    "        print(\"Running strategy at\", datetime.now())\n",
    "        # Add your trading strategy logic here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting apscheduler\n",
      "  Downloading APScheduler-3.11.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: tzlocal>=3.0 in c:\\users\\yassi\\appdata\\roaming\\python\\python312\\site-packages (from apscheduler) (5.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\yassi\\appdata\\roaming\\python\\python312\\site-packages (from tzlocal>=3.0->apscheduler) (2024.2)\n",
      "Downloading APScheduler-3.11.0-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: apscheduler\n",
      "Successfully installed apscheduler-3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install apscheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "def run_strategy():\n",
    "    print(\"Running strategy at\", datetime.now())\n",
    "    # Add your trading strategy logic here\n",
    "\n",
    "scheduler = BlockingScheduler()\n",
    "scheduler.add_job(run_strategy, 'cron', minute=0)  # Run at the start of every hour\n",
    "scheduler.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize Kraken Pro Exchange\n",
    "exchange = ccxt.kraken({\n",
    "    'apiKey': 'your_api_key',\n",
    "    'secret': 'your_api_secret'\n",
    "})\n",
    "\n",
    "# Fetch the latest OHLCV data point\n",
    "def fetch_latest_data(symbol, timeframe):\n",
    "    try:\n",
    "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=1)\n",
    "        latest_data = ohlcv[-1]\n",
    "        return {\n",
    "            'timestamp': pd.to_datetime(latest_data[0], unit='ms'),\n",
    "            'open': latest_data[1],\n",
    "            'high': latest_data[2],\n",
    "            'low': latest_data[3],\n",
    "            'close': latest_data[4],\n",
    "            'volume': latest_data[5]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching latest data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Append new data to CSV and maintain max length\n",
    "def append_to_csv_with_limit(data, filename, max_rows=3000):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    df = pd.DataFrame([data])\n",
    "    \n",
    "    if file_exists:\n",
    "        existing_df = pd.read_csv(filename)\n",
    "        combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        if len(combined_df) > max_rows:\n",
    "            combined_df = combined_df.iloc[-max_rows:]  # Keep only the last max_rows rows\n",
    "        combined_df.to_csv(filename, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "def load_data_from_csv(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Calculate moving averages on the dataset\n",
    "def calculate_moving_averages(df, fast_period, slow_period):\n",
    "    df['fast_ma'] = df['close'].rolling(window=fast_period).mean()\n",
    "    df['slow_ma'] = df['close'].rolling(window=slow_period).mean()\n",
    "    return df\n",
    "\n",
    "# Check crossover signals\n",
    "def check_crossover(df):\n",
    "    if len(df) < 2:\n",
    "        return None\n",
    "    if df['fast_ma'].iloc[-2] < df['slow_ma'].iloc[-2] and df['fast_ma'].iloc[-1] > df['slow_ma'].iloc[-1]:\n",
    "        return 'buy'\n",
    "    elif df['fast_ma'].iloc[-2] > df['slow_ma'].iloc[-2] and df['fast_ma'].iloc[-1] < df['slow_ma'].iloc[-1]:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Main function to run the strategy\n",
    "def run_strategy(symbol, timeframe, fast_period, slow_period, filename, max_rows):\n",
    "    print(f\"Starting Moving Average Crossover Strategy for {symbol} on {timeframe} timeframe.\")\n",
    "    while True:\n",
    "        latest_data = fetch_latest_data(symbol, timeframe)\n",
    "        if latest_data:\n",
    "            append_to_csv_with_limit(latest_data, filename, max_rows)\n",
    "            dataset = load_data_from_csv(filename)\n",
    "            dataset = calculate_moving_averages(dataset, fast_period, slow_period)\n",
    "            signal = check_crossover(dataset)\n",
    "            if signal == 'buy':\n",
    "                print(f\"Buy signal detected at {latest_data['timestamp']}\")\n",
    "            elif signal == 'sell':\n",
    "                print(f\"Sell signal detected at {latest_data['timestamp']}\")\n",
    "            else:\n",
    "                print(f\"No signal at {latest_data['timestamp']}\")\n",
    "        time.sleep(60)  # Wait for the next candle\n",
    "\n",
    "# Run the strategy\n",
    "\n",
    "symbol = 'BTC/USD'  # Trading pair\n",
    "timeframe = '1m'  # Timeframe\n",
    "fast_period = 5  # Fast moving average period\n",
    "slow_period = 20  # Slow moving average period\n",
    "csv_filename = 'market_data.csv'  # File to store historical data\n",
    "max_data_points = 3000  # Maximum number of rows in the CSV\n",
    "\n",
    "run_strategy(symbol, timeframe, fast_period, slow_period, csv_filename, max_data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
